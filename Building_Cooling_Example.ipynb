{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Cooling Loads Example\n",
    "### PIP Summer School 2018\n",
    "Phillippe Phanivong & Elpiniki Apostolaki â€“ Iosifidou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Problem\n",
    "\n",
    "One of the challenges in the power grid is that we can't tell customers when they can use electricity. They are buying a product from the utility and that product is reliable electricity when they want it. However, maybe we can incentivize people to reduce the amount of power they are using at certain times. However, to do this we need to know how customers are using their electricity and which ones have the ability to shift their consumption to different times of day. This notebook explores the cooling loads of different buildings to see if we can use climate data to predict the energy consumption of commerical building customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Where we're working out of\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "FOLDER_ID = \"building_lab\"\n",
    "DATA_FOLDER = \"Sacramento Building Load Models\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", FOLDER_ID)\n",
    "#A function to save figures easily\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    os.mkdir(FOLDER_ID)\n",
    "except:\n",
    "    print(\"Folder already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tmy3_data(climate_data, data_path=DATA_FOLDER):\n",
    "    csv_path = os.path.join(data_path, climate_data)\n",
    "    return pd.read_csv(csv_path,skiprows=[0], parse_dates=True)\n",
    "\n",
    "def load_building_data(building_data, data_path=DATA_FOLDER):\n",
    "    csv_path = os.path.join(data_path, building_data)\n",
    "    return pd.read_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmy3_data = load_tmy3_data(\"CA-Sacramento_Metro.tmy3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns we want \n",
    "tmy3_data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strips the year out of the first column\n",
    "tmy3_data.iloc[:,0] = tmy3_data.iloc[:,0].str.slice(0,5)\n",
    "\n",
    "#Important categories\n",
    "tmy3_data = tmy3_data.iloc[:,[0,1,31,37,40,43,46]]\n",
    "\n",
    "#Rename columns\n",
    "tmy3_data = tmy3_data.rename(columns={'Date (MM/DD/YYYY)':'date', 'Time (HH:MM)':'time',\n",
    "                           'Dry-bulb (C)': 'temp', 'RHum (%)':'humidity',\n",
    "                          'Pressure (mbar)': 'pressure', 'Wdir (degrees)': 'wind_dir',\n",
    "                          'Wspd (m/s)':'wind_speed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmy3_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notice describe() only shows the columns with integers or floats\n",
    "tmy3_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmy3_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmy3_data.hist(bins=50, figsize=(20,15))\n",
    "#save_fig(\"attribute_histogram_plots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building energy for a Sacramento Metro Airport TMY3 Medium Office building\n",
    "building_energy_data = load_building_data(\"RefBldgMediumOfficeNew2004_7.1_5.0_3B_USA_CA_LOS_ANGELES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_energy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The combined cooling energy with matching date and time from the feature set\n",
    "combined_set = pd.DataFrame(tmy3_data)\n",
    "combined_set = combined_set.join(building_energy_data.iloc[:,3])\n",
    "combined_set = combined_set.rename(columns={'Cooling:Electricity [kW](Hourly)':'cooling_load'})\n",
    "combined_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_set.hist(bins=50, figsize=(20,15))\n",
    "#save_fig(\"attribute_histogram_plots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cat = combined_set['date']\n",
    "date_cat_encoded, date_categories = date_cat.factorize()\n",
    "time_cat = combined_set['time']\n",
    "time_cat_encoded, time_categories = time_cat.factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_set = pd.DataFrame({'date_cat':date_cat_encoded,'time_cat':time_cat_encoded})\n",
    "combined_set = pd.concat([combined_set,tmy3_data.iloc[:,2:7],building_energy_data.iloc[:,3]],axis=1)\n",
    "combined_set = combined_set.rename(columns={'Cooling:Electricity [kW](Hourly)':'cooling_load'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_set.hist(bins=50, figsize=(20,15))\n",
    "#save_fig(\"attribute_histogram_plots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(combined_set, figsize = (12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attributes = ['cooling_load', 'temp', 'humidity', 'pressure']\n",
    "#scatter_matrix(combined_set[attributes], figsize = (12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = combined_set.corr()\n",
    "corr_matrix[\"cooling_load\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set,test_set = train_test_split(combined_set, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_safe = train_set.copy()\n",
    "corr_matrix = train_set.corr()\n",
    "corr_matrix[\"cooling_load\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.plot(kind='scatter', x = 'temp', y = 'cooling_load', alpha = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_train = train_set.drop('cooling_load', axis =1)\n",
    "label_set_train = train_set['cooling_load'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "scaled_feature_set_train = std_scaler.fit_transform(feature_set_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = sk.preprocessing.MinMaxScaler()\n",
    "min_max_feature_set_train = min_max_scaler.fit_transform(feature_set_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "#lin_reg.fit(feature_set_train, label_set_train)\n",
    "#lin_reg.fit(min_max_feature_set_train, label_set_train)\n",
    "lin_reg.fit(scaled_feature_set_train, label_set_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_energy_predictions = lin_reg.predict(feature_set_train)\n",
    "lin_mse = mean_squared_error(label_set_train, lin_energy_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_energy_predictions = lin_reg.predict(min_max_feature_set_train)\n",
    "lin_mse = mean_squared_error(label_set_train, lin_energy_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_energy_predictions = lin_reg.predict(scaled_feature_set_train)\n",
    "lin_mse = mean_squared_error(label_set_train, lin_energy_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor(random_state = 42)\n",
    "#tree_reg.fit(feature_set_train, label_set_train)\n",
    "#tree_reg.fit(min_max_feature_set_train, label_set_train)\n",
    "tree_reg.fit(scaled_feature_set_train, label_set_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_energy_predictions = tree_reg.predict(feature_set_train)\n",
    "tree_mse = mean_squared_error(label_set_train, tree_energy_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_energy_predictions = tree_reg.predict(min_max_feature_set_train)\n",
    "tree_mse = mean_squared_error(label_set_train, tree_energy_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_energy_predictions = tree_reg.predict(scaled_feature_set_train)\n",
    "tree_mse = mean_squared_error(label_set_train, tree_energy_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the plot.\n",
    "plt.clf()\n",
    "plt.plot(feature_set_train[\"temp\"], label_set_train, 'o', color='grey', label = 'Actual Output')\n",
    "plt.plot(feature_set_train[\"temp\"], lin_energy_predictions, 'o', color='red', label = 'Predicted Output')\n",
    "plt.xlabel(\"temperature\")\n",
    "plt.ylabel(\"Enegy\")\n",
    "plt.title(\"Linear Regression - Training Set\")\n",
    "plt.legend()\n",
    "#plt.savefig(\"linear_regression_train_set.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the plot.\n",
    "plt.clf()\n",
    "plt.plot(feature_set_train[\"humidity\"], label_set_train, 'o', color='grey', label = 'Actual Output')\n",
    "plt.plot(feature_set_train[\"humidity\"], tree_energy_predictions, 'o', color='red', label = 'Predicted Output')\n",
    "plt.xlabel(\"Humidity\")\n",
    "plt.ylabel(\"Enegy\")\n",
    "plt.title(\"Decision Tree Regression - Training Set\")\n",
    "plt.legend()\n",
    "plt.ylim((-1, 120))\n",
    "plt.xlim((-1,120))\n",
    "#plt.savefig(\"decision_tree_regression_train_set.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(lin_reg, scaled_feature_set_train, label_set_train,\n",
    "                             scoring= \"neg_mean_squared_error\", cv = 10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(tree_reg, scaled_feature_set_train, label_set_train,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "poly_features = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly_set_train = poly_features.fit_transform(min_max_feature_set_train)\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_poly_set_train, label_set_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "std_scaler = StandardScaler()\n",
    "poly_reg_pipe = LinearRegression()\n",
    "poly_pipe = Pipeline([(\"poly_features\", poly_features), (\"std_scaler\", std_scaler),(\"poly_reg\", poly_reg_pipe),])\n",
    "poly_pipe.fit(feature_set_train, label_set_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_energy_predictions = poly_reg.predict(X_poly_set_train)\n",
    "poly_mse = mean_squared_error(label_set_train, poly_energy_predictions)\n",
    "poly_rmse = np.sqrt(poly_mse)\n",
    "poly_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_energy_predictions = poly_pipe.predict(feature_set_train)\n",
    "poly_mse = mean_squared_error(label_set_train, poly_energy_predictions)\n",
    "poly_rmse = np.sqrt(poly_mse)\n",
    "poly_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try with different degrees of freedom\n",
    "poly_scores = cross_val_score(poly_pipe, feature_set_train, label_set_train,\n",
    "                             scoring= \"neg_mean_squared_error\", cv = 10)\n",
    "poly_rmse_scores = np.sqrt(-poly_scores)\n",
    "display_scores(poly_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "pipe_poly_features = PolynomialFeatures(degree=6, include_bias=False)\n",
    "pipe_std_scaler = StandardScaler()\n",
    "pipe_ridge_reg = Ridge(alpha=1, solver=\"cholesky\", random_state=42)\n",
    "ridge_pipe = Pipeline([(\"poly_features\", pipe_poly_features), (\"std_scaler\", pipe_std_scaler),(\"poly_reg\", pipe_ridge_reg),])\n",
    "ridge_pipe.fit(feature_set_train, label_set_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_energy_predictions = ridge_pipe.predict(feature_set_train)\n",
    "ridge_mse = mean_squared_error(label_set_train, ridge_energy_predictions)\n",
    "ridge_rmse = np.sqrt(ridge_mse)\n",
    "ridge_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try with different degrees of freedom\n",
    "ridge_scores = cross_val_score(ridge_pipe, feature_set_train, label_set_train,\n",
    "                             scoring= \"neg_mean_squared_error\", cv = 10)\n",
    "ridge_rmse_scores = np.sqrt(-ridge_scores)\n",
    "display_scores(ridge_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state = 42)\n",
    "forest_reg.fit(scaled_feature_set_train, label_set_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_energy_predictions = forest_reg.predict(scaled_feature_set_train)\n",
    "forest_mse = mean_squared_error(label_set_train, forest_energy_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_scores = cross_val_score(forest_reg, scaled_feature_set_train, label_set_train,\n",
    "                                 scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(forest_rmse_scores).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3,10,30,50,100], 'max_features': [2,4,6]},\n",
    "    {'bootstrap': [False], 'n_estimators':[3,10], 'max_features': [2,3,4]},\n",
    "    ]\n",
    "\n",
    "forest_reg_grid = RandomForestRegressor(random_state =42)\n",
    "grid_search = GridSearchCV(forest_reg_grid, param_grid, cv=5,\n",
    "                           scoring = \"neg_mean_squared_error\" , return_train_score=True)\n",
    "grid_search.fit(scaled_feature_set_train, label_set_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=7),\n",
    "    }\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions = param_distribs,\n",
    "                                n_iter=50, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(scaled_feature_set_train, label_set_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = rnd_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=rnd_search.best_estimator_\n",
    "\n",
    "X_test = test_set.drop('cooling_load', axis =1)\n",
    "y_test = test_set['cooling_load'].copy()\n",
    "\n",
    "X_test_prepared = std_scaler.fit_transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
